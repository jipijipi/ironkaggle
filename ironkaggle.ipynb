{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# IRON KAGGLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **shop_ID**: Unique identifier for each shop.\n",
    "- **day_of_the_week**: Encoded from 1 to 7, representing the day of the week.\n",
    "- **date**: Day, month, and year of the data point.\n",
    "- **number_of_customers**: Quantity of customers that visited the shop on that day.\n",
    "- **open**: Binary variable; 0 means the shop was closed, while 1 means it was open.\n",
    "- **promotion**: Binary variable; 0 means no promotions, 1 means there were promotions.\n",
    "- **state_holiday**: Encoded as 0, 'a', 'b', 'c', indicating the presence of a state holiday (0 if none). 'a', 'b', 'c' represent different state holidays.\n",
    "- **school_holiday**: Binary variable; 0 means no school holiday, 1 means there was a school holiday."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lib Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, root_mean_squared_error\n",
    "\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/sales.csv')\n",
    "sales_df = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(sales_df.shape)\n",
    "display(sales_df.head())\n",
    "display(sales_df.info())\n",
    "display(sales_df.isna().sum())\n",
    "display(sales_df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "# Split the dates\n",
    "sales_df['Year'] = sales_df['Date'].dt.year\n",
    "sales_df['Month'] = sales_df['Date'].dt.month\n",
    "sales_df['Day'] = sales_df['Date'].dt.day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average sales for each store\n",
    "#store_avg_sales = sales_df.groupby('Store_ID')['Sales'].mean()\n",
    "\n",
    "# Map the average sales back to the original dataframe\n",
    "#sales_df['Store_avg_sales'] = sales_df['Store_ID'].map(store_avg_sales)\n",
    "\n",
    "# Display the updated dataframe\n",
    "display(sales_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is the day a weekend?\n",
    "sales_df['Is_weekend'] = sales_df['Day_of_week'].apply(lambda x: 1 if x >= 6 else 0)\n",
    "\n",
    "# Add a column to indicate if promotions and holidays are concurrent\n",
    "#sales_df['Promo_Holiday'] = sales_df.apply(lambda row: 1 if row['Promotion'] == 1 and (row['State_holiday_a'] or row['State_holiday_b'] or row['State_holiday_c']) else 0, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_stats = sales_df.groupby('Store_ID').agg({\n",
    "    'Sales': ['mean', 'std', 'median'],\n",
    "    'Nb_customers_on_day': ['mean', 'std', 'median'],\n",
    "    'Promotion': 'mean',  # Promotion frequency\n",
    "    'School_holiday': 'mean',  # School holiday frequency\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten column names\n",
    "store_stats.columns = ['Store_ID'] + [\n",
    "    f'Store_{x[0]}_{x[1]}' for x in store_stats.columns[1:]\n",
    "]\n",
    "\n",
    "# Calculate store performance quartiles\n",
    "store_stats['Store_sales_quartile'] = pd.qcut(\n",
    "    store_stats['Store_Sales_mean'], \n",
    "    q=4, \n",
    "    labels=['Q1', 'Q2', 'Q3', 'Q4']\n",
    ")\n",
    "\n",
    "sales_df = sales_df.merge(store_stats, on='Store_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts the state holiday column to multiple binary columns\n",
    "sales_df = pd.get_dummies(sales_df, columns=['State_holiday','Store_sales_quartile'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DF Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(sales_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = sales_df.corr()\n",
    "\n",
    "# just for the target column\n",
    "corr_matrix_target = corr_matrix[['Sales']]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix_target, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define feature & target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Drop open 0?\n",
    "features = sales_df.drop(columns=['Sales','Date', 'True_index','Store_ID'])\n",
    "target = sales_df['Sales']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Try different sample sizes\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Try different scalers\n",
    "\n",
    "normalizer = MinMaxScaler()\n",
    "\n",
    "normalizer.fit(X_train)\n",
    "\n",
    "X_train_norm = normalizer.transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.DataFrame(X_train_norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = 3\n",
    "max_depth = None\n",
    "n_estimators = None\n",
    "max_samples = None\n",
    "max_leafs_nodes = None\n",
    "max_features = None\n",
    "\n",
    "model = KNeighborsRegressor(n_neighbors=n_neighbors, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = 10\n",
    "max_depth = None\n",
    "n_estimators = None\n",
    "max_samples = None\n",
    "max_leafs_nodes = None\n",
    "max_features = None\n",
    "\n",
    "model = KNeighborsRegressor(n_neighbors=n_neighbors, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = None\n",
    "max_depth = None\n",
    "n_estimators = None\n",
    "max_samples = None\n",
    "max_leafs_nodes = None\n",
    "max_features = None\n",
    "\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = None\n",
    "max_depth = 10\n",
    "n_estimators = None\n",
    "max_samples = None\n",
    "max_leafs_nodes = None\n",
    "max_features = None\n",
    "\n",
    "model = DecisionTreeRegressor(max_depth=max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = None\n",
    "max_depth = 1000\n",
    "n_estimators = None\n",
    "max_samples = None\n",
    "max_leafs_nodes = None\n",
    "max_features = None\n",
    "\n",
    "model = DecisionTreeRegressor(max_depth=max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = None\n",
    "max_depth = 1000\n",
    "n_estimators = None\n",
    "max_samples = None\n",
    "max_leafs_nodes = None\n",
    "max_features = None\n",
    "\n",
    "model = DecisionTreeRegressor(max_depth=max_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = None\n",
    "max_depth = None\n",
    "n_estimators = 100\n",
    "max_samples = 1000\n",
    "max_leafs_nodes = None\n",
    "max_features = None\n",
    "estimator = LinearRegression()\n",
    "\n",
    "model = BaggingRegressor(estimator, n_estimators=n_estimators, max_samples=max_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = 10\n",
    "max_depth = None\n",
    "n_estimators = 100\n",
    "max_samples = 1000\n",
    "max_leafs_nodes = None\n",
    "max_features = None\n",
    "estimator = KNeighborsRegressor(n_neighbors=n_neighbors, n_jobs=-1)\n",
    "\n",
    "model = BaggingRegressor(estimator, n_estimators=n_estimators, max_samples=max_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = None\n",
    "max_depth = 1000\n",
    "n_estimators = 100\n",
    "max_samples = 1000\n",
    "max_leafs_nodes = None\n",
    "max_features = None\n",
    "estimator = DecisionTreeRegressor(max_depth=max_depth)\n",
    "\n",
    "model = BaggingRegressor(estimator, n_estimators=n_estimators, max_samples=max_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = None\n",
    "max_depth = 1000\n",
    "n_estimators = 100\n",
    "max_samples = 1000\n",
    "max_leafs_nodes = None\n",
    "max_features = None\n",
    "estimator = DecisionTreeRegressor(max_depth=max_depth)\n",
    "\n",
    "model = BaggingRegressor(estimator, n_estimators=n_estimators, max_samples=max_samples, bootstrap=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = None\n",
    "max_depth = 1000\n",
    "n_estimators = 100\n",
    "max_samples = None\n",
    "max_leafs_nodes = None\n",
    "max_features = None\n",
    "estimator = None\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = None\n",
    "max_depth = 100\n",
    "n_estimators = 100\n",
    "max_samples = None\n",
    "max_leafs_nodes = None\n",
    "max_features = None\n",
    "estimator = DecisionTreeRegressor(max_depth=max_depth)\n",
    "\n",
    "model = AdaBoostRegressor(n_estimators=n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = 10\n",
    "max_depth = None\n",
    "n_estimators = 100\n",
    "max_samples = None\n",
    "max_leafs_nodes = None\n",
    "max_features = None\n",
    "estimator = KNeighborsRegressor(n_neighbors=n_neighbors, n_jobs=-1)\n",
    "\n",
    "model = AdaBoostRegressor(n_estimators=n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = None\n",
    "max_depth = None\n",
    "n_estimators = 100\n",
    "max_samples = None\n",
    "max_leafs_nodes = None\n",
    "max_features = None\n",
    "estimator = LinearRegression()\n",
    "\n",
    "model = AdaBoostRegressor(n_estimators=n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = None\n",
    "max_depth = 100\n",
    "n_estimators = 100\n",
    "max_samples = None\n",
    "max_leafs_nodes = None\n",
    "max_features = None\n",
    "estimator = None\n",
    "\n",
    "model = GradientBoostingRegressor(max_depth=max_depth,  n_estimators=n_estimators, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = None\n",
    "max_depth = 20\n",
    "n_estimators = 100\n",
    "max_samples = None\n",
    "max_leafs_nodes = None\n",
    "max_features = None\n",
    "estimator = None\n",
    "\n",
    "model = GradientBoostingRegressor(max_depth=max_depth,  n_estimators=n_estimators, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = None\n",
    "max_depth = 100\n",
    "n_estimators = 100\n",
    "max_samples = None\n",
    "max_leafs_nodes = None\n",
    "max_features = None\n",
    "estimator = None\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_norm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the regressor name and the estimator name programmatically\n",
    "regressor_name = type(model).__name__\n",
    "estimator_name = type(estimator).__name__\n",
    "\n",
    "print(f\"Regressor: {regressor_name}, Estimator: {estimator_name}\")\n",
    "\n",
    "model_name = type(model).__name__\n",
    "\n",
    "pred = model.predict(X_test_norm)\n",
    "\n",
    "mae = mean_absolute_error(pred, y_test)\n",
    "rmse = root_mean_squared_error(pred, y_test)\n",
    "r2 = model.score(X_test_norm, y_test)\n",
    "\n",
    "\n",
    "# Create a DataFrame with the current model results\n",
    "current_results = pd.DataFrame([{\n",
    "    'Model': f'{model_name} > {estimator_name}' if 'estimator_name' in locals() else model_name,\n",
    "    'n_neighbors': n_neighbors,\n",
    "    'max_depth': max_depth,\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_samples': max_samples,\n",
    "    'max_leafs_nodes': max_leafs_nodes,\n",
    "    'max_features' : max_features,\n",
    "    'MAE': mae,\n",
    "    'RMSE': rmse,\n",
    "    'R2_score': r2,\n",
    "}])\n",
    "\n",
    "display(current_results)\n",
    "\n",
    "file_name = 'results.csv'\n",
    "# Check if the file already exists\n",
    "if os.path.isfile(file_name):\n",
    "    # If the file exists, append the new results without writing the header\n",
    "    current_results.to_csv(file_name, mode='a', header=False, index=False)\n",
    "else:\n",
    "    # If the file does not exist, create it and write the header\n",
    "    current_results.to_csv(file_name, mode='w', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
